\graphicspath{ {./images} }

%!TEX root = ../thesis.tex
\chapter{Methods}
\label{ch:methods}

\chapter{The Simulink Model}
\begin{figure}
	\centerline{\includegraphics[scale=0.035]{HexapodModel_Overview}}
	\caption{Simulink Model Overview}
	\label{Simulink Model Overview}
\end{figure}

\section{Model of the Hexapod}

\begin{figure}
	\centerline{\includesvg[scale=0.7]{Simulink/Simulink_PhysicalHexapodOverview}}
	\caption{Hexapod Model Overview}
	\label{Hexapod Model Overview}
\end{figure}

\begin{figure}
	\centerline{\includesvg[scale=0.6]{Simulink/Simulink_HexapodLegOverview}}
	\caption{Model of Hexapod Leg}
	\label{Hexapod Leg}
\end{figure}


The hexapod model we used in this work is the \textit{PhantomX MK4} developed by \textit{Trossen Robotics}.
The company provides a .urdf file(Unified Robotics Description Format) of the robot which is imported into the MATLAB environment.
MATLAB is then able to convert the file into a Simulink model consisting of blocks from the Simscape library.

\todo{Insert images of hexapod model}
The main body of the hexapod robot is represented by a rigid body and a main coordinate frame.
Each of the robots legs consists of 3 rigid bodies(coxa, femur and tibia) which are connected to each other by 2 joints.
A third joint then attaches the coxa, and thus the whole leg, to the main body.
Each joint has 1 (rotational) DoF.
To position each rigid body and joint correctly, so called rigid transformations are used to translate and rotate each part.

Each of the models joints can receive a torque to be applied as input and output various sensory data such as the joints position, velocity and acceleration. 
To simplify the model, we did not model the physical servo motors and instead used this direct torque input to the joints.

From a top level perspective, the hexapod model consists of the main body(thorax) and the 6 legs.
This system receives as input the torque to be applied on each joint and outputs sensory data taken from these joints, namely the joints position, velocity and acceleration.
In this work only the data about the current joint positions is utilized, but to allow for further expansion on the model, such as optimizing for minimal energy consumption, joint velocity and acceleration are provided as well.
Integration of the joint position over time would yield the same result, but we decided for ease of use to include the data explicitly.

To encapsulate the system and only provide the necessary inputs and outputs, the system is placed inside a subsystem.
This also allows for the duplication of the hexapod system, so that in future research it can also be used in multi-agent simulations.

\section{Environment}
To validate the robot model and to provide a place for the robot to learn the coordination rules of its legs, we constructed a simple test environment.
The environment currently only consists of a horizontal plane, but can expanded to include more complex terrain with little effort.
Some examples which we experimented with but did not include in this thesis are inclined planes and also obstacles on the ground.

\section{Controller}
The controller is responsible for the hexapods locomotion.
It controls the movement of the robots six legs according to a predefined gait.
As inputs, the controller receives the sensory data from the hexapod model.
According to this data the controller outputs the torques to be applied to each joint.

\begin{figure}
	\centerline{\includegraphics[scale=0.03]{HexapodController}}
	\caption{Controller Overview}
	\label{Controller Overview}
\end{figure}
Each of the hexapods legs is controlled by a separate control unit which receives the information of the legs joint sensors as input and computes the torques to be applied to its joints as output.
The control unit for a leg receives the frequency for the swing-stance cycle, duty-percentage of the swing phase and swing-initiation signal as coordination inputs.
This information can either come from a static gait definition, in which the parameters for each leg are statically configured, or can be provided by a reinforcement learning agent.
The agent receives observations from the environment and hexapod model as well as a reward signal and outputs actions in the form as mentioned above.






\todo{Viel tiefer ins Detail gehen}
\todo{Bilder}

\section{Learning Leg Coordination}
The leg coordination problem can be considered a Markov decision process(MDP).
The MDP is a 5-tuple $\mathcal{\{S,A,P,R,\gamma\}}$, where $\mathcal{S}$ is a finite set of states, $\mathcal{A}$ is a finite set of actions, $\mathcal{P}$ is a state-transition probability matrix ($\mathcal{P}_{ss'}^a=\mathbb{P}[S_{t+1}=s' | S_t=s, A_t=a]$), $\mathcal{R}_s^a$ is a reward function ($\mathcal{R}_s^a = \mathbb{E}[R_{t+1} | S_t=s, A_t=a]$) and $\gamma \in [0,1]$ is a discount factor.


